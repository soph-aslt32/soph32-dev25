# memo

## 要件

データがcsv形式で与えられる．
データは，メインデータと詳細データに分けられる．
メインデータは，メインデータ群の中に「親」として定義づけることが可能なデータが存在する．

- keyとして自然言語的な記述がある．
  - AをBにする
  - Cを使用する
- keyと対応するvalueとして，数値がある．
  - AをBにする:
    - n_a = 100
    - n_b = 8000
    - ...
- 各keyがメインデータ群の中のどのデータを参照しているかどうかの記述がOptionとして存在する．
  - Option = None or str
- 各key, valueは本来メインデータの一部と対応しているものだが，明示的な対応mapは無い．

## 要求

新規のメインデータと詳細データのkeyが与えられた時，valueに相当するデータを推論するAIがほしい．

## GPT

```md
とても面白い課題ですね。  
このような「自然言語で表記されたデータから，意味的に一致するものを見つけて数値を取得する」というタスクは，近年の自然言語処理（NLP）技術の進展によって実現可能な方法がいくつも考えられます。

## 考えられる手法一覧
大きくは次の2つの流れに分かれます。
1. 文字列ベース（ルールベース・類似度計算）
2. 意味ベース（ベクトル化・埋め込みモデル）

---

## 1. 文字列ベースの手法
### (1) 正規化＋部分一致・編集距離
- ステップ：
  - ひらがな・カタカナ・漢字の統一
  - 表記ゆれ（全角/半角・英語/カタカナなど）の正規化
  - 正規表現・部分一致検索
  - レーベンシュタイン距離（編集距離）で近いものを探す
- メリット：
  - 実装が容易
- デメリット：
  - 意味的な違いには弱い（「東京」と「首都」は無理）

---

### (2) 辞書・ルールベースマッピング
- ステップ：
  - 事前に類義語辞書を用意
  - 「内容」を辞書変換して統一表現に変換
- 使用ツール：
  - WordNet
  - 自作辞書
- メリット：
  - 精度高い
- デメリット：
  - 辞書メンテナンスが大変

---

## 2. 意味ベースの手法（自然言語処理モデル利用）
### (3) Bag of Words（BoW）＋TF-IDF＋Cos類似度
- ステップ：
  - BoW化（単語の出現数）
  - TF-IDFベクトル化
  - コサイン類似度で検索
- メリット：
  - 意味的に近い表現にも対応
- デメリット：
  - 文脈考慮は弱い

---

### (4) Word2Vec / FastTextによる平均ベクトル＋類似度
- ステップ：
  - 各単語をWord2VecやFastTextでベクトル化
  - 全体の平均ベクトルを計算
  - 類似度検索
- メリット：
  - 類義語・表記ゆれに強い
- デメリット：
  - 単語単位のモデルなので長文は弱い

---

### (5) Sentence-BERT（SBERT）による文埋め込み
- ステップ：
  - 「内容」をSBERTで文ベクトル化
  - 類似度（コサイン類似度）で検索
- メリット：
  - 文の意味全体を考慮
  - 表記ゆれに強い
- デメリット：
  - モデルサイズ大
  - 事前学習モデルの選定が重要

---

### (6) ChatGPT APIやOpenAI Embedding APIを利用
- ステップ：
  - OpenAIのtext-embedding-ada-002などで文ベクトル化
  - 類似度検索（ベクトルDB利用）
- メリット：
  - 最新のモデルで非常に高精度
- デメリット：
  - コストがかかる
  - インターネット接続前提

---

## その他の手法
### (7) 類義語展開＋検索
- 言語モデルで「内容A」の類義語を複数生成し，全てで検索
- GPTに「これと同じ意味の表現を10個教えて」と依頼
- 部分一致などと組み合わせ

---

### (8) ベクトルデータベース（Vector DB）の活用
- 構築した埋め込みベクトルを専用DBに格納
  - 例：FAISS，Milvus，Pinecone
- 意味的に近いものを高速に検索可能

---

## 全体まとめ表

| 手法 | 特徴 | 強み | 弱み |
|------|------|------|------|
| 正規化＋部分一致 | 手軽 | 実装が簡単 | 意味対応が弱い |
| 辞書・ルール | カスタマイズ性高 | 精度高い | 保守が大変 |
| TF-IDF | 古典的NLP | 部分的な意味対応 | 長文弱い |
| Word2Vec | 単語レベル意味対応 | 表記ゆれ強い | 長文弱い |
| SBERT | 文全体意味対応 | 高精度 | モデル大 |
| OpenAI API | 最新技術 | 最強 | コスト |
| 類義語展開 | アドホック対応 | 柔軟 | 自動化が困難 |
| Vector DB | ベクトル管理専用DB | 高速・高精度 | 構築コスト |

---

必要に応じて，これらの手法を組み合わせてハイブリッド型にすることも可能です。  

---

## 最後に質問
この中で興味があるもの，または実装を考えている環境・制約はありますか？（オンプレ？クラウド？Python？）  
より具体的に提案できます！
```
